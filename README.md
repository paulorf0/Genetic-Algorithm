# NeuroEvolution: Treinamento de Rede Neural via Algoritmo Gen√©tico

Este projeto demonstra a implementa√ß√£o de um sistema de **Neuroevolu√ß√£o**, onde os pesos e vieses de uma Rede Neural Artificial (RNA) s√£o otimizados utilizando um Algoritmo Gen√©tico (AG), em vez do tradicional *Backpropagation*. O exemplo pr√°tico resolve o problema do **XOR** (Ou Exclusivo).

## üöÄ Como Funciona

O projeto combina duas bibliotecas customizadas em C++:

### 1. Rede Neural (`neural_network.hpp`)
* **Arquitetura:** *Feedforward* densa (Multilayer Perceptron).
* **Topologia do Teste:** `[2, 2, 1]` (2 neur√¥nios na entrada, 2 na camada oculta, 1 na sa√≠da).
* **Ativa√ß√£o:** Sigmoide.
* **Representa√ß√£o:** A rede aceita um vetor linear (DNA) que √© mapeado internamente para as matrizes de pesos e vetores de vi√©s usando a biblioteca `Eigen`.

### 2. Algoritmo Gen√©tico (`genetic_algorithm.hpp`)
O AG evolui uma popula√ß√£o de vetores de n√∫meros reais (o DNA da rede) para minimizar o erro quadr√°tico.
* **Popula√ß√£o:** 200 indiv√≠duos.
* **Sele√ß√£o:** Torneio (K-Best).
* **Cruzamento (Crossover):** Ponto √∫nico (Single Point) com elitismo (Top 5 mantidos).
* **Muta√ß√£o:** Distribui√ß√£o Normal adicionada aos genes para explora√ß√£o estoc√°stica.
* **Fitness:** Inverso do erro quadr√°tico m√©dio em rela√ß√£o √†s sa√≠das esperadas do XOR.

---

## üìä Resultados da Execu√ß√£o

Abaixo est√° o log de uma execu√ß√£o bem-sucedida onde o algoritmo convergiu, encontrando uma solu√ß√£o que satisfaz o problema do XOR.

```text
Final: 
Epoch: 213
Fitness: 10.0889
Id: 116
Dna: ('-4.44953' '3.91753' '-4.55155' '4.83153' '-2.16117' '2.03077' '5.59438' '-4.60265' '1.74622')

Entrada: {0, 0) | Sa√≠da da rede: 0.165192 | Esperado: 0
Entrada: {0, 1) | Sa√≠da da rede: 0.883073 | Esperado: 1
Entrada: {1, 0) | Sa√≠da da rede: 0.805667 | Esperado: 1
Entrada: {1, 1) | Sa√≠da da rede: 0.123882 | Esperado: 0
